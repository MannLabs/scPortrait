import numpy as np
import matplotlib.pyplot as plt
from sklearn.mixture import GaussianMixture
from scipy.stats import norm
import os

from skimage.morphology import disk, dilation, erosion
from collections import defaultdict

from sparcscore.pipeline.base import Logable
from sparcscore.processing.preprocessing import downsample_img_pxs


class BaseFilter(Logable):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
    
    def get_unique_ids(self, mask):
        return np.unique(mask)[1:]  # to remove the background

    def update_mask(self, mask, ids_to_remove):
        """
        Update the given mask by setting the values corresponding to the specified IDs to 0.

        Parameters
        ----------
        mask : numpy.ndarray
            The mask to be updated.
        ids_to_remove : numpy.ndarray
            The IDs to be removed from the mask.

        Returns
        -------
        numpy.ndarray
            The updated mask with the specified IDs set to 0.
        """
        return np.where(np.isin(mask, ids_to_remove), 0, mask)

    def downsample_mask(self, mask):
        return downsample_img_pxs(mask, N=self.downsampling_factor)

    def upscale_mask_basic(self, mask, erosion_dilation=False):
        mask = mask.repeat(self.downsampling_factor, axis=0).repeat(
            self.downsampling_factor, axis=1
        )

        if erosion_dilation:
            mask = erosion(mask, footprint=disk(self.smoothing_kernel_size))
            mask = dilation(mask, footprint=disk(self.smoothing_kernel_size))

        return mask

class SizeFilter(BaseFilter):
    """
    Filter class for removing objects from a mask based on their size.

    This class provides methods to remove objects from a segmentation mask based on their size.
    If specified the objects are filtered using a threshold range passed by the user. Otherwise,
    this threshold range will be automatically calculated.

    To automatically calculate the threshold range, a gaussian mixture model will be fitted to the data.
    Per default, the number of components is set to 2, as it is assumed that the objects in the mask can be divided into two
    groups: small and large objects. The small objects constitute segmentation artefacts (partial masks that are
    frequently generated by segmentation models like e.g. cellpose) while the large objects
    represent the actual cell masks of interest. Using the fitted model, the filtering thresholds are calculated
    to remove all cells that fall outside of the given confidence interval.

    Parameters
    ----------
    filter_threshold : tuple of floats, optional
        The lower and upper thresholds for object size filtering. If not provided, it will be automatically calculated.
    label : str, optional
        The label of the mask. Default is "segmask".
    log : bool, optional
        Whether to take the logarithm of the size of the objects before fitting the normal distribution. Default is True.
        By enabling this option, the filter will better be able to distinguish between small and large objects.
    plot_qc : bool, optional
        Whether to plot quality control figures. Default is True.
    directory : str, optional
        The directory to save the generated figures. If not provided, the current working directory will be used.
    confidence_interval : float, optional
        The confidence interval for calculating the filtering threshold. Default is 0.95.

    Examples
    --------
    >>> # Create a SizeFilter object
    >>> filter = SizeFilter(filter_threshold=(100, 200), label="my_mask")
    >>> # Apply the filter to a mask
    >>> filtered_mask = filter.filter(input_mask)
    >>> # Get the object IDs to be removed
    >>> ids_to_remove = filter.get_ids_to_remove(input_mask)
    >>> # Update the mask by removing the identified object IDs
    >>> updated_mask = filter.update_mask(input_mask, ids_to_remove)

    """

    def __init__(
        self,
        filter_threshold=None,
        label="segmask",
        log=True,
        plot_qc=True,
        directory=None,
        confidence_interval=0.95,
        n_components=2,
        population_to_keep="largest",
        *args,
        **kwargs,
    ):
        super().__init__(*args, **kwargs)

        self.log_values = log
        self.plot_qc = plot_qc
        self.label = label
        self.filter_threshold = filter_threshold
        self.confidence_interval = confidence_interval
        self.n_components = n_components
        self.population_to_keep = population_to_keep

        # if no directory is provided, use the current working directory
        if directory is not None:
            self.directory = directory
        else:
            self.directory = os.getcwd()

        self.ids_to_remove = None

    def plot_gaussian_model(
        self,
        counts,
        means,
        variances,
        weights,
        threshold,
        bins=30,
        figsize=(5, 5),
        alpha=0.5,
        save_figure=True,
    ):
        """
        Plot a histogram of the provided data with fitted Gaussian distributions.

        Parameters
        ----------
        counts : array_like
            The input data array.
        means : array_like
            The means of the Gaussian distributions.
        variances : array_like
            The variances of the Gaussian distributions.
        weights : array_like
            The weights of the Gaussian distributions.
        threshold : tuple
            The lower and upper threshold values.
        label : str
            The label for the histogram.
        n_components : int
            The number of Gaussian components.
        bins : int, optional
            The number of bins in the histogram. Default is 30.
        figsize : tuple, optional
            The size of the figure. Default is (5, 5).
        alpha : float, optional
            The transparency of the histogram bars. Default is 0.5.
        directory : str, optional
            The directory to save the figure. Default is None.
        save_figure : bool, optional
            Whether to save the figure. Default is True.

        Returns
        -------
        fig : matplotlib.figure.Figure
            The generated figure.
        """

        # generate valuerange over which to visualize the distributions
        x = np.linspace(min(counts), max(counts), 1000)

        # initialize the figure
        fig, axs = plt.subplots(1, 1, figsize=figsize)

        # visualize the base histogram
        axs.hist(counts, bins=bins, density=True, alpha=alpha, label=self.label)

        # visualize the fitted Gaussian distributions
        for i in range(self.n_components):
            _pdf = norm.pdf(x, means[i], np.sqrt(variances[i])) * weights[i]
            axs.plot(x, _pdf, "-r", label=f"Gaussian {i}")

        # visualize the threshold values as dotted lines
        axs.axvline(
            threshold[0],
            color="blue",
            linestyle="--",
            label=f"Threshold Lower: {threshold[0]:.2f}",
        )
        axs.axvline(
            threshold[1],
            color="blue",
            linestyle="--",
            label=f"Threshold Upper: {threshold[1]:.2f}",
        )

        # format the plot
        axs.legend()
        axs.set_title("Histogram and Fitted Distributions")
        fig.tight_layout()
        plt.close(fig)

        # automatically save figure to directory if parameter is specified
        if save_figure:
            fig.savefig(os.path.join(self.directory, f"{self.label}_bimodal_model.png"))

        return fig

    def plot_histogram(
        self,
        values,
        label=None,
        bins=30,
        alpha=0.5,
        figsize=(5, 5),
        save_figure=True,
    ):
        """
        Plot a histogram of the given values.

        Parameters
        ----------
        values : array-like
            The values to be plotted.
        label : str, optional
            The label for the histogram plot.
        bins : int, optional
            The number of bins in the histogram. Default is 30.
        alpha : float, optional
            The transparency of the histogram bars. Default is 0.5.
        figsize : tuple, optional
            The size of the figure. Default is (5, 5).
        save_figure : bool, optional
            Whether to save the figure as an image. Default is True.

        Returns
        -------
        fig : matplotlib.figure.Figure
            The generated figure object.
        """

        fig, axs = plt.subplots(1, 1, figsize=figsize)
        axs.hist(values, bins=bins, density=True, alpha=alpha)
        axs.set_title(label)
        axs.set_xlabel("value")
        axs.set_ylabel("density")
        fig.tight_layout()
        plt.close(fig)

        if save_figure:
            fig.savefig(os.path.join(self.directory, f"{label}_histogram.png"))

        return fig

    def calculate_filtering_threshold(self, counts):
        """
        Calculate the filtering thresholds for the given counts.

        Parameters
        ----------
        counts : numpy.ndarray
            The counts of the data.

        Returns
        -------
        tuple
            A tuple containing the lower and upper filtering thresholds.

        Examples
        --------
        >>> import numpy as np
        >>> from sparcscore.processing.filtering import SizeFilter
        >>> np.random.seed(0)
        >>> counts1 = np.random.normal(0, 1, 1000)
        >>> counts2 = np.random.normal(3, 1, 1000)
        >>> counts = np.concatenate((counts1, counts2))
        >>> size_filter = SizeFilter(log = False)
        >>> thresholds = size_filter.calculate_filtering_threshold(counts)
        >>> thresholds
        (1.0785720179538172, 4.911918901671607)
        """

        # take the log of the counts if log_values is True
        if self.log_values:
            data = np.log(counts)
        else:
            data = counts.copy()

        # reshape the data to have the correct dimensions for fitting the model
        data_reshaped = data.reshape(-1, 1)

        # initialize and fit the model
        gmm = GaussianMixture(n_components=self.n_components, random_state=0)
        gmm.fit(data_reshaped)

        # Get the means, variances, and weights of the fitted Gaussians
        means = gmm.means_.flatten()
        variances = gmm.covariances_.flatten()
        weights = gmm.weights_

        # get index of the model which matches to the population of cells that should be kept
        if self.population_to_keep == "largest":
            idx = np.argmax(means)
        elif self.population_to_keep == "smallest":
            idx = np.argmin(means)

        # calculate the thresholds for the selected model using the given confidence interval
        mu = means[idx]
        sigma = np.sqrt(variances[idx])

        percent = 1 - self.confidence_interval
        lower = percent / 2
        upper = 1 - percent / 2

        lower_threshold = mu + sigma * norm.ppf(lower)
        upper_threshold = mu + sigma * norm.ppf(upper)

        threshold = (lower_threshold, upper_threshold)

        fig = self.plot_gaussian_model(
            counts=data,
            means=means,
            variances=variances,
            weights=weights,
            threshold=threshold,
        )

        if self.plot_qc:
            plt.show(fig)  # show the figure if plot_qc is True

        if self.log_values:
            self.threshold = np.exp(threshold)
        else:
            self.threshold = threshold

        self.log(
            f"Calculated threshold for {self.label} with {self.confidence_interval * 100}% confidence interval: {self.threshold}"
        )
        return self.threshold

    def get_ids_to_remove(self, input_mask):
        """
        Get the IDs to remove from the input mask based on the filtering threshold.

        Parameters
        ----------
        input_mask : ndarray
            The input mask as a numpy array.

        Returns
        -------
        ndarray
            An array containing the IDs to remove from the input mask.

        Notes
        -----
        This function calculates the filtering threshold based on the pixel counts of the input mask.
        It then identifies the IDs that are outside of the chosen threshold range and returns them as an array.

        The filtering threshold can be automatically calculated if not provided.
        """

        # get value counts of the mask
        counts = np.unique(input_mask, return_counts=True)
        pixel_counts = counts[1][1:]

        fig = self.plot_histogram(pixel_counts, self.label)
        plt.close(fig)

        if self.plot_qc:
            plt.show(fig)

        # automatically calculate filtering threshold if not provided
        if self.filter_threshold is None:
            self.filter_threshold = self.calculate_filtering_threshold(pixel_counts)

        ids_remove = []
        _ids = counts[0][1:][np.where(pixel_counts < self.filter_threshold[0])]
        ids_remove.extend(_ids)

        self.log(
            f"Found {len(_ids)} ids to remove from {self.label} mask which are smaller than the chosen threshold range {self.filter_threshold}."
        )

        _ids = counts[0][1:][np.where(pixel_counts > self.filter_threshold[1])]
        ids_remove.extend(_ids)

        self.log(
            f"Found {len(_ids)} ids to remove from {self.label} mask which are bigger than the chosen threshold range {self.filter_threshold}."
        )

        self.ids_to_remove = ids_remove

    def filter(self, input_mask):
        """
        Filter the input mask based on the filtering threshold.

        Parameters
        ----------
        input_mask : ndarray
            The input mask to be filtered. Expected shape is (X, Y)

        Returns
        -------
        filtered_mask : ndarray
            The filtered mask after settings the IDs which do not fullfill the filtering criteria to 0.

        """
        if self.ids_to_remove is None:
            self.get_ids_to_remove(input_mask)
        return self.update_mask(input_mask, self.ids_to_remove)

class MatchNucleusCytosolIds(BaseFilter):
    def __init__(
        self,
        filtering_threshold=0.5,
        downsampling_factor=None,
        erosion_dilation=True,
        smoothing_kernel_size=7,
        *args,
        **kwargs,
    ):
        super().__init__(*args, **kwargs)
        self.filtering_threshold = filtering_threshold

        #set up downsampling
        if downsampling_factor is not None:
            self.downsample = True
            self.downsampling_factor = downsampling_factor
            self.erosion_dilation = erosion_dilation
            self.smoothing_kernel_size = smoothing_kernel_size
        else:
            self.downsample = False

        self.nucleus_mask = None
        self.cytosol_mask = None
        
        self._nucleus_lookup_dict = {}
        self.nuclei_discard_list = []
        self.cytosol_discard_list = []

    def load_masks(self, nucleus_mask, cytosol_mask):
        #masks are only loaded once (if already loaded nothing happens)
        if self.downsample:
            if self.nucleus_mask is None:
                self.nucleus_mask = self.downsample_mask(nucleus_mask)
            if self.cytosol_mask is None:
                 self.cytosol_mask = self.downsample_mask(cytosol_mask)
        else:
            if self.nucleus_mask is None:
                self.nucleus_mask = nucleus_mask
            if self.cytosol_mask is None:
                self.cytosol_mask = cytosol_mask
    
    def update_cytosol_mask(self, cytosol_mask):
        # now we have all the nucleus cytosol pairs we can filter the masks
        updated = np.zeros_like(cytosol_mask, dtype=bool)

        for nucleus_id, cytosol_id in self.nucleus_lookup_dict.items():
                # set the cytosol pixels to the nucleus_id if not previously updated
                condition = np.logical_and(
                    cytosol_mask == cytosol_id, ~updated
                )
                cytosol_mask[condition] = nucleus_id
                updated = np.logical_or(
                    updated, condition
                )
        return(cytosol_mask)
           
    def update_masks(self):

        nucleus_mask = self.update_mask(self.nucleus_mask, self.nuclei_discard_list)
        cytosol_mask = self.update_cytosol_mask(self.cytosol_mask)

        if self.downsample:
            nucleus_mask = self.upscale_mask_basic(nucleus_mask, self.erosion_dilation)
            cytosol_mask = self.upscale_mask_basic(self.cytosol_mask, self.erosion_dilation)
        
        return nucleus_mask, cytosol_mask
    
    def match_nucleus_id(self, nucleus_id):
        """
        Match the given nucleus ID to a cytosol ID based on the overlapping area.

        Parameters
        ----------
        nucleus_mask : numpy.ndarray
            The nucleus mask.
        cytosol_mask : numpy.ndarray
            The cytosol mask.
        nucleus_id : int
            The nucleus ID to be matched.

        Returns
        -------
        int
            The matched cytosol ID.
        """
        # get the coordinates of the nucleus
        nucleus_pixels = np.where(self.nucleus_mask == nucleus_id)

        # check if those indices are not background in the cytosol mask
        potential_cytosol = self.cytosol_mask[nucleus_pixels]

        # if there is a cytosolID in the area of the nucleus proceed, else continue with a new nucleus
        if np.all(potential_cytosol != 0):
            unique_cytosol, counts = np.unique(potential_cytosol, return_counts=True)
            all_counts = np.sum(counts)
            cytosol_proportions = counts / all_counts

            if np.any(cytosol_proportions >= self.filtering_threshold):
                # get the cytosol_id with max proportion
                cytosol_id = unique_cytosol[
                    np.argmax(cytosol_proportions >= self.filtering_threshold)
                ]
                if cytosol_id != 0:
                    self._nucleus_lookup_dict[nucleus_id] = cytosol_id
                    return cytosol_id
                else:
                    self.nuclei_discard_list.append(nucleus_id)
                    return None
            else:
                self.nuclei_discard_list.append(nucleus_id)
                return None
        else:
            self.nuclei_discard_list.append(nucleus_id)
            return None
        
    def initialize_lookup_table(self):
        all_nucleus_ids = self.get_unique_ids(self.nucleus_mask)

        for nucleus_id in all_nucleus_ids:
            self.match_nucleus_id(nucleus_id)
    
    def count_cytosol_occurances(self):
        cytosol_count = defaultdict(int)

        # Count the occurrences of each cytosol value
        for cytosol in self._nucleus_lookup_dict.values():
            cytosol_count[cytosol] += 1
        
        self.cytosol_count = cytosol_count
        
    def check_for_unassigned_cytosols(self):
        all_cytosol_ids = self.get_unique_ids(self.cytosol_mask)

        for cytosol_id in all_cytosol_ids:
            if cytosol_id not in self._nucleus_lookup_dict.values():
                self.cytosol_discard_list.append(cytosol_id)
    
    def identify_multinucleated_cells(self):
        for nucleus, cytosol in self._nucleus_lookup_dict.items():
            if self.cytosol_count[cytosol] > 1:
                self.nuclei_discard_list.append(nucleus)
                self.cytosol_discard_list.append(cytosol)

    def cleanup_filtering_lists(self):
        self.nuclei_discard_list = list(set(self.nuclei_discard_list))
        self.cytosol_discard_list = list(set(self.cytosol_discard_list))

    def cleanup_lookup_dictionary(self):
        _cleanup = []
        for nucleus_id, cytosol_id in self._nucleus_lookup_dict.items():
            if nucleus_id in self.nuclei_discard_list:
                _cleanup.append(nucleus_id)
            if cytosol_id in self.cytosol_discard_list:
                _cleanup.append(nucleus_id)
        
        for nucleus in _cleanup:
            del self._nucleus_lookup_dict[nucleus]

    def generate_lookup_table(self, nucleus_mask, cytosol_mask):    
        self.load_masks(nucleus_mask, cytosol_mask)
        self.initialize_lookup_table()
        self.count_cytosol_occurances()
        self.check_for_unassigned_cytosols()
        self.identify_multinucleated_cells()
        self.cleanup_filtering_lists()
        self.cleanup_lookup_dictionary()

        self.nucleus_lookup_dict = self._nucleus_lookup_dict #save final result to a new variable name

        return(self.nucleus_lookup_dict)

    def filter(self, nucleus_mask, cytosol_mask):
        
        self.load_masks(nucleus_mask, cytosol_mask) 
        self.generate_lookup_table(nucleus_mask, cytosol_mask)
        
        return self.update_masks()